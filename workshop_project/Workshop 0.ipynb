{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# regression predictive modelling problem using the boston housing dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.datasets import boston_housing\n",
    "\n",
    "(X,Y), (x_test, y_test) = boston_housing.load_data(test_split=0.2)\n",
    "\n",
    "# import sklearn tools for validation\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global settings:\n",
    "g_standardize_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model scaffold\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, kernel_initializer='normal', input_dim=13, activation=\"relu\"))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "    # compile model with mean square error-error function\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# including the scikit-learn modules for analysis gives greater flecxibility\n",
    "# use fixed random seed to allow for reproducible results\n",
    "seed=7\n",
    "np.random.seed(seed)\n",
    "\n",
    "def train_and_output(estimator, x_data, y_data):\n",
    "    kfold = KFold(n_splits=10, random_state=seed)\n",
    "    results = cross_val_score(estimator, x_data,y_data, cv=kfold)\n",
    "    return results\n",
    "\n",
    "# using skikit-learn's pipeline tools to create the standard estimators (squash the data)\n",
    "# should improve model output:\n",
    "def create_pipeline(model, standardize=False):\n",
    "    if standardize: # run with standardased data:\n",
    "        estimators=[]\n",
    "        estimators.append(('standardize', StandardScaler()))\n",
    "        estimators.append(('mlp', KerasRegressor(build_fn=model, epochs=50, batch_size=5, verbose=0)))\n",
    "        pipeline = Pipeline(estimators)\n",
    "\n",
    "#         kfold=KFold(n_splits=10, random_state=seed)\n",
    "#         results = cross_val_score(pipeline, X,Y, cv=kfold)\n",
    "#         print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "    else:\n",
    "        pipeline = KerasRegressor(build_fn=model, epochs=100, batch_size=5, verbose=0)\n",
    "        \n",
    "    return pipeline\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model: 22.78 (9.01) MSE\n"
     ]
    }
   ],
   "source": [
    "pipeline = create_pipeline(baseline_model, g_standardize_data)\n",
    "results = train_and_output(pipeline, X, Y)\n",
    "print(\"Baseline model: %.2f (%.2f) MSE\" % (abs(results.mean()), results.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Layer-model: 17.84 (8.86) MSE\n"
     ]
    }
   ],
   "source": [
    "# testing with a larger model:\n",
    "# should improve model output:\n",
    "\n",
    "def larger_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, input_dim=13, kernel_initializer='normal'))\n",
    "    \n",
    "    #compile:             \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "pipeline = create_pipeline(larger_model, True)\n",
    "results = train_and_output(pipeline, X, Y)\n",
    "print(\"2 Layer-model: %.2f (%.2f) MSE\" % (abs(results.mean()), results.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 neuron wide-model: 20.08, (9.67) MSE\n"
     ]
    }
   ],
   "source": [
    "# testing with a 'wider' model:\n",
    "def wider_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "pipeline = create_pipeline(wider_model, True)\n",
    "results = train_and_output(pipeline, X, Y)\n",
    "print(\"20 neuron wide-model: %.2f, (%.2f) MSE\" % (abs(results.mean()), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 580us/step\n"
     ]
    }
   ],
   "source": [
    "# the built in keras trainer:\n",
    "\n",
    "model = baseline_model()\n",
    "estimator = model.fit(X, Y, epochs=100, batch_size=5, verbose=0)\n",
    "\n",
    "# evaluation:\n",
    "loss_and_metrics=model.evaluate(x_test, y_test, batch_size=5)\n",
    "print(\"loss: {}\".format(loss_and_metrics)) # does not output the stddev."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: prediction\n",
    "classes = model.predict(x_test, batch_size=5)\n",
    "\n",
    "# predict using the scipy-learn setup:\n",
    "def mse(self, prediction, actual):\n",
    "    # todo: use numpy arrays\n",
    "    errors = []\n",
    "    for i in range(0, len(prediction)):\n",
    "        errors[i] = pow(prediction[i]-actual[i], 2)\n",
    "\n",
    "    return mean(errors)\n",
    "\n",
    "# NOTE:: uses the pipeline object\n",
    "pipeline.fit(self.X,self.Y)\n",
    "prediction = estimator.predict(x_test)\n",
    "\n",
    "print(\"prediction: %.2f\" % self.mse(prediction, self.y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
